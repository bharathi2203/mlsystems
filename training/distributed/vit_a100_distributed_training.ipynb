{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "280edd00",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Distributed Training ViT on A100\n",
    "\n",
    "ViT-Base (ViT-B/16): ~86M parameters trained on ImageNet-1K with comprehensive GPU profiling\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "- **Model:** ViT-Base/16 (~86M parameters)\n",
    "- **Dataset:** ImageNet-1K (1000 classes)\n",
    "- **Batch size:** 32 per GPU\n",
    "- **Learning rate:** 3e-4 (AdamW)\n",
    "- **Warmup steps:** 10,000\n",
    "- **Total epochs:** 300\n",
    "- **Image size:** 224x224\n",
    "- **Patch size:** 16x16\n",
    "- **Mixed precision:** FP16\n",
    "- **Weight decay:** 0.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a390f55",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## ViT-Base Architecture\n",
    "\n",
    "**Vision Transformer (ViT-B/16) Overview:**\n",
    "- **Input:** 224x224 RGB images\n",
    "- **Patch size:** 16x16 (=> 196 patches per image)\n",
    "- **Embedding dim:** 768\n",
    "- **Transformer blocks:** 12\n",
    "- **Attention heads:** 12\n",
    "- **MLP hidden dim:** 3072\n",
    "- **Classification head:** Linear layer\n",
    "\n",
    "**Parameter Calculation:**\n",
    "- Patch embedding: (16*16*3)*768 + 768 = 590,592\n",
    "- Position embedding: (196+1)*768 = 151,296 (197 patches + CLS token)\n",
    "- Each transformer block:\n",
    "  - Multi-head self-attention: 3*768*768 + 768*768 = 2,359,296\n",
    "  - MLP: 768*3072 + 3072*768 = 4,718,592\n",
    "  - LayerNorms: 2*768*2 = 3,072\n",
    "  - Total per block: ~7.08M\n",
    "- 12 blocks: ~85M\n",
    "- Classification head: 768*1000 + 1000 = 769,000\n",
    "- **Total:** ~86.6M parameters\n",
    "\n",
    "**Memory Requirement (Training):**\n",
    "- Model params (fp32): 86.6M * 4B = ~346MB\n",
    "- Model params (fp16): 86.6M * 2B = ~173MB\n",
    "- Activations (batch=32, fp16): ~2-3GB\n",
    "- Gradients (fp32): ~346MB\n",
    "- Optimizer states (AdamW): ~692MB\n",
    "- **Total (mixed precision):** ~4-5GB\n",
    "\n",
    "**Computation per Forward Pass:**\n",
    "- Patch embedding: 196 * 768 * 3 * 16² = ~590M FLOPs\n",
    "- Self-attention (per layer): 4 * 197 * 768² = ~467M FLOPs\n",
    "- MLP (per layer): 2 * 197 * 768 * 3072 = ~926M FLOPs\n",
    "- Total per layer: ~1.4G FLOPs\n",
    "- **Total forward:** ~17.5 GFLOPs/image\n",
    "- **Total (forward+backward):** ~52.5 GFLOPs/image\n",
    "- For batch=32: ~1.68 TFLOPs/step\n",
    "\n",
    "**A100 Performance:**\n",
    "- Theoretical peak (FP16): 312 TFLOPs\n",
    "- Memory bandwidth: 2TB/s\n",
    "- Expected utilization: 30-50% (due to memory-bound operations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6acbabf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Environment Setup and Profiling Tools Installation\n",
    "\n",
    "This section automatically detects the environment (Colab vs local) and installs necessary profiling tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa0fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "\n",
    "# Detect environment\n",
    "def is_colab():\n",
    "    \"\"\"Check if running in Google Colab\"\"\"\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install package with pip\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "def install_apt_package(package):\n",
    "    \"\"\"Install apt package (Ubuntu/Debian)\"\"\"\n",
    "    subprocess.check_call([\"apt-get\", \"update\", \"-qq\"])\n",
    "    subprocess.check_call([\"apt-get\", \"install\", \"-y\", package])\n",
    "\n",
    "# Environment detection\n",
    "COLAB = is_colab()\n",
    "LOCAL = not COLAB\n",
    "\n",
    "print(f\"Environment: {'Colab' if COLAB else 'Local'}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Python: {sys.version}\")\n",
    "\n",
    "# Install required packages\n",
    "required_packages = [\n",
    "    \"torch>=2.0.0\",\n",
    "    \"torchvision\",\n",
    "    \"tensorboard\",\n",
    "    \"wandb\",\n",
    "    \"timm\",\n",
    "    \"transformers\",\n",
    "    \"datasets\",\n",
    "    \"pillow\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"nvidia-ml-py3\"\n",
    "]\n",
    "\n",
    "print(\"\\nInstalling Python packages...\")\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        install_package(package)\n",
    "        print(f\"[INSTALLED] {package}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[FAILED] {package}: {e}\")\n",
    "\n",
    "# Colab-specific setup\n",
    "if COLAB:\n",
    "    print(\"\\nSetting up Google Colab environment...\")\n",
    "    \n",
    "    # Install CUDA profiling tools (if available)\n",
    "    try:\n",
    "        # Check CUDA version\n",
    "        cuda_version = subprocess.check_output([\"nvcc\", \"--version\"]).decode()\n",
    "        print(f\"CUDA version: {cuda_version.split('release')[1].split(',')[0].strip()}\")\n",
    "        \n",
    "        # Try to install nsight tools (may not work in standard Colab)\n",
    "        print(\"Attempting to install NVIDIA profiling tools...\")\n",
    "        try:\n",
    "            install_apt_package(\"wget\")\n",
    "            # Download and install nsight systems (simplified)\n",
    "            subprocess.run([\n",
    "                \"wget\", \"-q\", \n",
    "                \"https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb\"\n",
    "            ])\n",
    "            subprocess.run([\"dpkg\", \"-i\", \"cuda-keyring_1.0-1_all.deb\"])\n",
    "            subprocess.run([\"apt-get\", \"update\", \"-qq\"])\n",
    "            # Note: Full nsight installation may require custom runtime\n",
    "            print(\"WARNING: Full Nsight tools require custom Colab runtime\")\n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: Nsight installation failed (expected in standard Colab): {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"WARNING: CUDA tools not available: {e}\")\n",
    "    \n",
    "    # Enable TensorBoard extension\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"tensorboard-plugin-profile\"])\n",
    "        print(\"[INSTALLED] TensorBoard profiling extension\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Local setup\n",
    "elif LOCAL:\n",
    "    print(\"\\nSetting up local environment...\")\n",
    "    \n",
    "    # Check if running on Linux (required for some tools)\n",
    "    if platform.system() == \"Linux\":\n",
    "        try:\n",
    "            # Install profiling tools\n",
    "            print(\"Installing NVIDIA profiling tools...\")\n",
    "            install_apt_package(\"cuda-nvprof\")\n",
    "            install_apt_package(\"cuda-nsight\")\n",
    "            print(\"[INSTALLED] NVIDIA profiling tools\")\n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: Failed to install NVIDIA tools: {e}\")\n",
    "            print(\"    Please install manually or run with sudo\")\n",
    "    else:\n",
    "        print(\"WARNING: Some profiling tools are Linux-only\")\n",
    "\n",
    "print(\"\\nEnvironment setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3089bd1e",
   "metadata": {},
   "source": [
    "## ViT-Base Model Implementation\n",
    "\n",
    "Complete PyTorch implementation of ViT-Base/16 with distributed training support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21689146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import vit_b_16\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Custom ViT implementation (alternative to torchvision)\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_patches = (img_size // patch_size) ** 2\n",
    "        \n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W) -> (B, embed_dim, H/P, W/P) -> (B, embed_dim, N) -> (B, N, embed_dim)\n",
    "        x = self.proj(x)  # (B, embed_dim, H/P, W/P)\n",
    "        x = x.flatten(2)  # (B, embed_dim, N)\n",
    "        x = x.transpose(1, 2)  # (B, N, embed_dim)\n",
    "        return x\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim=768, num_heads=12, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        \n",
    "        self.qkv = nn.Linear(embed_dim, embed_dim * 3)\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        attn = (q @ k.transpose(-2, -1)) * (self.head_dim ** -0.5)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        \n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, embed_dim=768, mlp_ratio=4.0, dropout=0.1):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(embed_dim * mlp_ratio)\n",
    "        self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim=768, num_heads=12, mlp_ratio=4.0, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = MultiHeadSelfAttention(embed_dim, num_heads, dropout)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = MLP(embed_dim, mlp_ratio, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_channels=3, num_classes=1000,\n",
    "                 embed_dim=768, depth=12, num_heads=12, mlp_ratio=4.0, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, self.patch_embed.n_patches + 1, embed_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "        \n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat([cls_tokens, x], dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        x = x[:, 0]  # Use CLS token\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count model parameters\"\"\"\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, trainable\n",
    "\n",
    "# Create model\n",
    "def create_vit_model(num_classes=1000, use_pretrained=True):\n",
    "    if use_pretrained:\n",
    "        # Use torchvision pretrained model\n",
    "        model = vit_b_16(weights='IMAGENET1K_V1')\n",
    "        if num_classes != 1000:\n",
    "            model.heads.head = nn.Linear(model.heads.head.in_features, num_classes)\n",
    "    else:\n",
    "        # Use custom implementation\n",
    "        model = VisionTransformer(num_classes=num_classes)\n",
    "    \n",
    "    total_params, trainable_params = count_parameters(model)\n",
    "    print(f\"Model parameters: {total_params:,} total, {trainable_params:,} trainable\")\n",
    "    print(f\"Model size: {total_params * 4 / 1024**2:.1f} MB (fp32)\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test the model\n",
    "if __name__ == \"__main__\":\n",
    "    model = create_vit_model(num_classes=1000, use_pretrained=False)\n",
    "    x = torch.randn(2, 3, 224, 224)\n",
    "    y = model(x)\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c206514",
   "metadata": {},
   "source": [
    "## Profiling and Monitoring Setup\n",
    "\n",
    "This section sets up comprehensive GPU profiling including PyTorch Profiler, NVIDIA tools, and custom metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.profiler\n",
    "import psutil\n",
    "import GPUtil\n",
    "import threading\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, deque\n",
    "import subprocess\n",
    "import nvidia_ml_py3 as nvml\n",
    "\n",
    "# Initialize NVIDIA ML\n",
    "try:\n",
    "    nvml.nvmlInit()\n",
    "    print(\"[INITIALIZED] NVIDIA ML library\")\n",
    "except:\n",
    "    print(\"WARNING: NVIDIA ML library not available\")\n",
    "\n",
    "class GPUMonitor:\n",
    "    \"\"\"Real-time GPU monitoring\"\"\"\n",
    "    def __init__(self, device_id=0, interval=0.1):\n",
    "        self.device_id = device_id\n",
    "        self.interval = interval\n",
    "        self.monitoring = False\n",
    "        self.metrics = defaultdict(deque)\n",
    "        self.thread = None\n",
    "        \n",
    "    def start(self):\n",
    "        \"\"\"Start monitoring in background thread\"\"\"\n",
    "        self.monitoring = True\n",
    "        self.thread = threading.Thread(target=self._monitor_loop)\n",
    "        self.thread.start()\n",
    "        \n",
    "    def stop(self):\n",
    "        \"\"\"Stop monitoring\"\"\"\n",
    "        self.monitoring = False\n",
    "        if self.thread:\n",
    "            self.thread.join()\n",
    "            \n",
    "    def _monitor_loop(self):\n",
    "        \"\"\"Main monitoring loop\"\"\"\n",
    "        while self.monitoring:\n",
    "            try:\n",
    "                # GPU metrics via nvidia-ml-py3\n",
    "                handle = nvml.nvmlDeviceGetHandleByIndex(self.device_id)\n",
    "                \n",
    "                # Memory info\n",
    "                mem_info = nvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "                gpu_memory_used = mem_info.used / 1024**3  # GB\n",
    "                gpu_memory_total = mem_info.total / 1024**3  # GB\n",
    "                gpu_memory_util = (mem_info.used / mem_info.total) * 100\n",
    "                \n",
    "                # GPU utilization\n",
    "                util = nvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "                gpu_util = util.gpu\n",
    "                \n",
    "                # Temperature\n",
    "                temp = nvml.nvmlDeviceGetTemperature(handle, nvml.NVML_TEMPERATURE_GPU)\n",
    "                \n",
    "                # Power\n",
    "                power = nvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # Watts\n",
    "                \n",
    "                # Store metrics\n",
    "                timestamp = time.time()\n",
    "                self.metrics['timestamp'].append(timestamp)\n",
    "                self.metrics['gpu_util'].append(gpu_util)\n",
    "                self.metrics['gpu_memory_used'].append(gpu_memory_used)\n",
    "                self.metrics['gpu_memory_util'].append(gpu_memory_util)\n",
    "                self.metrics['temperature'].append(temp)\n",
    "                self.metrics['power'].append(power)\n",
    "                \n",
    "                # Keep only last 1000 samples\n",
    "                for key in self.metrics:\n",
    "                    if len(self.metrics[key]) > 1000:\n",
    "                        self.metrics[key].popleft()\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"Monitoring error: {e}\")\n",
    "                \n",
    "            time.sleep(self.interval)\n",
    "            \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get current statistics\"\"\"\n",
    "        if not self.metrics['gpu_util']:\n",
    "            return {}\n",
    "            \n",
    "        return {\n",
    "            'gpu_util_avg': sum(self.metrics['gpu_util']) / len(self.metrics['gpu_util']),\n",
    "            'gpu_util_max': max(self.metrics['gpu_util']),\n",
    "            'gpu_memory_max': max(self.metrics['gpu_memory_used']),\n",
    "            'gpu_memory_avg': sum(self.metrics['gpu_memory_used']) / len(self.metrics['gpu_memory_used']),\n",
    "            'temperature_max': max(self.metrics['temperature']),\n",
    "            'power_avg': sum(self.metrics['power']) / len(self.metrics['power']),\n",
    "        }\n",
    "        \n",
    "    def plot_metrics(self, save_path=None):\n",
    "        \"\"\"Plot monitoring metrics\"\"\"\n",
    "        if not self.metrics['timestamp']:\n",
    "            print(\"No metrics to plot\")\n",
    "            return\n",
    "            \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        timestamps = list(self.metrics['timestamp'])\n",
    "        start_time = timestamps[0]\n",
    "        times = [(t - start_time) for t in timestamps]\n",
    "        \n",
    "        # GPU Utilization\n",
    "        axes[0, 0].plot(times, list(self.metrics['gpu_util']))\n",
    "        axes[0, 0].set_title('GPU Utilization (%)')\n",
    "        axes[0, 0].set_ylabel('Utilization %')\n",
    "        \n",
    "        # Memory Usage\n",
    "        axes[0, 1].plot(times, list(self.metrics['gpu_memory_used']), label='Used')\n",
    "        axes[0, 1].set_title('GPU Memory Usage (GB)')\n",
    "        axes[0, 1].set_ylabel('Memory (GB)')\n",
    "        \n",
    "        # Temperature\n",
    "        axes[1, 0].plot(times, list(self.metrics['temperature']))\n",
    "        axes[1, 0].set_title('GPU Temperature (°C)')\n",
    "        axes[1, 0].set_ylabel('Temperature (°C)')\n",
    "        \n",
    "        # Power\n",
    "        axes[1, 1].plot(times, list(self.metrics['power']))\n",
    "        axes[1, 1].set_title('GPU Power Usage (W)')\n",
    "        axes[1, 1].set_ylabel('Power (W)')\n",
    "        \n",
    "        for ax in axes.flat:\n",
    "            ax.set_xlabel('Time (s)')\n",
    "            ax.grid(True)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "class TorchProfiler:\n",
    "    \"\"\"PyTorch profiler wrapper\"\"\"\n",
    "    def __init__(self, log_dir=\"./profiler_logs\", trace_handler=None):\n",
    "        self.log_dir = Path(log_dir)\n",
    "        self.log_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        if trace_handler is None:\n",
    "            trace_handler = torch.profiler.tensorboard_trace_handler(str(self.log_dir))\n",
    "            \n",
    "        self.profiler = torch.profiler.profile(\n",
    "            schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "            on_trace_ready=trace_handler,\n",
    "            record_shapes=True,\n",
    "            profile_memory=True,\n",
    "            with_stack=True,\n",
    "            with_flops=True,\n",
    "            with_modules=True\n",
    "        )\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.profiler.__enter__()\n",
    "        return self.profiler\n",
    "        \n",
    "    def __exit__(self, *args):\n",
    "        self.profiler.__exit__(*args)\n",
    "\n",
    "def profile_model_flops(model, input_tensor):\n",
    "    \"\"\"Profile model FLOPs using torch.profiler\"\"\"\n",
    "    model.eval()\n",
    "    with torch.profiler.profile(with_flops=True) as prof:\n",
    "        with torch.no_grad():\n",
    "            _ = model(input_tensor)\n",
    "    \n",
    "    # Calculate total FLOPs\n",
    "    total_flops = sum([item.flops for item in prof.key_averages()])\n",
    "    return total_flops\n",
    "\n",
    "def measure_memory_usage(model, input_tensor, device):\n",
    "    \"\"\"Measure peak memory usage\"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    \n",
    "    model.train()\n",
    "    output = model(input_tensor)\n",
    "    loss = output.sum()\n",
    "    loss.backward()\n",
    "    \n",
    "    peak_memory = torch.cuda.max_memory_allocated(device) / 1024**3  # GB\n",
    "    return peak_memory\n",
    "\n",
    "def benchmark_throughput(model, input_shape, device, batch_sizes=[1, 8, 16, 32], num_runs=10):\n",
    "    \"\"\"Benchmark model throughput\"\"\"\n",
    "    results = {}\n",
    "    model.eval()\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        input_tensor = torch.randn(batch_size, *input_shape, device=device)\n",
    "        \n",
    "        # Warmup\n",
    "        for _ in range(5):\n",
    "            with torch.no_grad():\n",
    "                _ = model(input_tensor)\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # Measure\n",
    "        times = []\n",
    "        for _ in range(num_runs):\n",
    "            start = time.time()\n",
    "            with torch.no_grad():\n",
    "                _ = model(input_tensor)\n",
    "            torch.cuda.synchronize()\n",
    "            times.append(time.time() - start)\n",
    "        \n",
    "        avg_time = sum(times) / len(times)\n",
    "        throughput = batch_size / avg_time\n",
    "        \n",
    "        results[batch_size] = {\n",
    "            'avg_time': avg_time,\n",
    "            'throughput': throughput,\n",
    "            'images_per_second': throughput\n",
    "        }\n",
    "        \n",
    "        print(f\"Batch size {batch_size}: {throughput:.1f} images/sec\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test GPU monitoring\n",
    "print(\"Testing GPU monitoring...\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f\"Using GPU {device}: {torch.cuda.get_device_name(device)}\")\n",
    "    \n",
    "    # Quick GPU info\n",
    "    memory_total = torch.cuda.get_device_properties(device).total_memory / 1024**3\n",
    "    print(f\"Total GPU memory: {memory_total:.1f} GB\")\n",
    "else:\n",
    "    print(\"CUDA not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5877cb",
   "metadata": {},
   "source": [
    "## Training without any optimizations\n",
    "\n",
    "Basic ViT training loop with comprehensive profiling and monitoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d22e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def get_imagenet_loaders(data_path=\"/tmp/imagenet\", batch_size=32, num_workers=4):\n",
    "    \"\"\"Create ImageNet data loaders (using FakeData for demo)\"\"\"\n",
    "    \n",
    "    # ImageNet transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Use FakeData for demo (replace with real ImageNet)\n",
    "    train_dataset = datasets.FakeData(\n",
    "        size=1000, image_size=(3, 224, 224), \n",
    "        num_classes=1000, transform=train_transform\n",
    "    )\n",
    "    val_dataset = datasets.FakeData(\n",
    "        size=200, image_size=(3, 224, 224), \n",
    "        num_classes=1000, transform=val_transform\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, \n",
    "        shuffle=True, num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, \n",
    "        shuffle=False, num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "def calculate_accuracy(outputs, targets, topk=(1, 5)):\n",
    "    \"\"\"Calculate top-k accuracy\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = targets.size(0)\n",
    "    \n",
    "    _, pred = outputs.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(targets.view(1, -1).expand_as(pred))\n",
    "    \n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, criterion, device, epoch, \n",
    "                profiler=None, gpu_monitor=None):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # Metrics\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Measure accuracy\n",
    "        acc1, acc5 = calculate_accuracy(outputs, targets, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1.item(), images.size(0))\n",
    "        top5.update(acc5.item(), images.size(0))\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # Profiler step\n",
    "        if profiler:\n",
    "            profiler.step()\n",
    "        \n",
    "        # Log progress\n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch: [{epoch}][{i}/{len(train_loader)}] '\n",
    "                  f'Time {batch_time.val:.3f} ({batch_time.avg:.3f}) '\n",
    "                  f'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  f'Loss {losses.val:.4f} ({losses.avg:.4f}) '\n",
    "                  f'Acc@1 {top1.val:.3f} ({top1.avg:.3f}) '\n",
    "                  f'Acc@5 {top5.val:.3f} ({top5.avg:.3f})')\n",
    "            \n",
    "            # GPU stats\n",
    "            if gpu_monitor:\n",
    "                stats = gpu_monitor.get_stats()\n",
    "                if stats:\n",
    "                    print(f'GPU: {stats.get(\"gpu_util_avg\", 0):.1f}% util, '\n",
    "                          f'{stats.get(\"gpu_memory_avg\", 0):.1f}GB mem, '\n",
    "                          f'{stats.get(\"temperature_max\", 0):.0f}°C, '\n",
    "                          f'{stats.get(\"power_avg\", 0):.0f}W')\n",
    "        \n",
    "        # Limit iterations for demo\n",
    "        if i >= 50:\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        'loss': losses.avg,\n",
    "        'top1': top1.avg,\n",
    "        'top5': top5.avg,\n",
    "        'batch_time': batch_time.avg,\n",
    "        'data_time': data_time.avg\n",
    "    }\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, targets) in enumerate(val_loader):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            acc1, acc5 = calculate_accuracy(outputs, targets, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1.item(), images.size(0))\n",
    "            top5.update(acc5.item(), images.size(0))\n",
    "            \n",
    "            # Limit for demo\n",
    "            if i >= 10:\n",
    "                break\n",
    "    \n",
    "    print(f'Validation: Loss {losses.avg:.4f} Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}')\n",
    "    \n",
    "    return {\n",
    "        'loss': losses.avg,\n",
    "        'top1': top1.avg,\n",
    "        'top5': top5.avg\n",
    "    }\n",
    "\n",
    "def main_training_basic():\n",
    "    \"\"\"Main training function without optimizations\"\"\"\n",
    "    print(\"Starting basic ViT training...\")\n",
    "    \n",
    "    # Setup\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Model\n",
    "    model = create_vit_model(num_classes=1000, use_pretrained=False)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Data\n",
    "    batch_size = 32 if torch.cuda.is_available() else 8\n",
    "    train_loader, val_loader = get_imagenet_loaders(batch_size=batch_size)\n",
    "    \n",
    "    # Training setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.3)\n",
    "    \n",
    "    # Profiling setup\n",
    "    gpu_monitor = None\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_monitor = GPUMonitor(device_id=device.index)\n",
    "        gpu_monitor.start()\n",
    "    \n",
    "    # Benchmark model\n",
    "    print(\\\"\\\\nModel benchmarking...\\\")\\n    with torch.no_grad():\\n        dummy_input = torch.randn(1, 3, 224, 224, device=device)\\n        \\n        # FLOPs\\n        total_flops = profile_model_flops(model, dummy_input)\\n        print(f\\\"Model FLOPs: {total_flops / 1e9:.2f} GFLOPs\\\")\\n        \\n        # Memory\\n        peak_memory = measure_memory_usage(model, dummy_input, device)\\n        print(f\\\"Peak memory: {peak_memory:.2f} GB\\\")\\n        \\n        # Throughput\\n        if torch.cuda.is_available():\\n            throughput_results = benchmark_throughput(model, (3, 224, 224), device)\\n    \\n    # Training with profiling\\n    results = []\\n    \\n    with TorchProfiler(log_dir=\\\"./logs/basic_training\\\") as profiler:\\n        for epoch in range(2):  # Limited epochs for demo\\n            print(f\\\"\\\\n=== Epoch {epoch + 1} ===\\\")\\n            \\n            # Train\\n            train_metrics = train_epoch(\\n                model, train_loader, optimizer, criterion, device, \\n                epoch, profiler, gpu_monitor\\n            )\\n            \\n            # Validate\\n            val_metrics = validate(model, val_loader, criterion, device)\\n            \\n            # Store results\\n            epoch_results = {\\n                'epoch': epoch + 1,\\n                'train': train_metrics,\\n                'val': val_metrics\\n            }\\n            \\n            if gpu_monitor:\\n                epoch_results['gpu_stats'] = gpu_monitor.get_stats()\\n            \\n            results.append(epoch_results)\\n            \\n            # Save checkpoint\\n            checkpoint = {\\n                'epoch': epoch + 1,\\n                'model_state_dict': model.state_dict(),\\n                'optimizer_state_dict': optimizer.state_dict(),\\n                'train_loss': train_metrics['loss'],\\n                'val_loss': val_metrics['loss'],\\n            }\\n            torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')\\n    \\n    # Cleanup\\n    if gpu_monitor:\\n        gpu_monitor.stop()\\n        gpu_monitor.plot_metrics(save_path='gpu_metrics_basic.png')\\n    \\n    # Save results\\n    with open('training_results_basic.json', 'w') as f:\\n        json.dump(results, f, indent=2)\\n    \\n    print(\\\"\\\\nBasic training completed!\\\")\\n    print(\\\"Check the following files:\\\")\\n    print(\\\"   - training_results_basic.json (metrics)\\\")\\n    print(\\\"   - gpu_metrics_basic.png (GPU monitoring)\\\")\\n    print(\\\"   - ./logs/basic_training/ (PyTorch profiler traces)\\\")\\n    print(\\\"   - checkpoint_epoch_*.pth (model checkpoints)\\\")\\n    \\n    return results\\n\\n# Run basic training\\nif __name__ == \\\"__main__\\\":\\n    results = main_training_basic()\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368e3e2",
   "metadata": {},
   "source": [
    "## DeepSpeed ZeRO Stage 1\n",
    "\n",
    "ZeRO-1 partitions optimizer states across GPUs, reducing memory usage while maintaining performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install DeepSpeed if not available\n",
    "try:\n",
    "    import deepspeed\n",
    "    print(\"[AVAILABLE] DeepSpeed\")\n",
    "except ImportError:\n",
    "    print(\"Installing DeepSpeed...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"deepspeed\"])\n",
    "    import deepspeed\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import os\n",
    "import json\n",
    "\n",
    "# DeepSpeed ZeRO-1 Configuration\n",
    "def get_deepspeed_config_zero1():\n",
    "    \"\"\"DeepSpeed configuration for ZeRO Stage 1\"\"\"\n",
    "    return {\n",
    "        \"train_batch_size\": 32,\n",
    "        \"train_micro_batch_size_per_gpu\": 8,\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"AdamW\",\n",
    "            \"params\": {\n",
    "                \"lr\": 3e-4,\n",
    "                \"weight_decay\": 0.3,\n",
    "                \"bias_correction\": True\n",
    "            }\n",
    "        },\n",
    "        \"scheduler\": {\n",
    "            \"type\": \"WarmupLR\",\n",
    "            \"params\": {\n",
    "                \"warmup_min_lr\": 0,\n",
    "                \"warmup_max_lr\": 3e-4,\n",
    "                \"warmup_num_steps\": 1000\n",
    "            }\n",
    "        },\n",
    "        \"zero_optimization\": {\n",
    "            \"stage\": 1,\n",
    "            \"allgather_partitions\": True,\n",
    "            \"allgather_bucket_size\": 2e8,\n",
    "            \"overlap_comm\": True,\n",
    "            \"reduce_scatter\": True,\n",
    "            \"reduce_bucket_size\": 2e8,\n",
    "            \"contiguous_gradients\": True\n",
    "        },\n",
    "        \"fp16\": {\n",
    "            \"enabled\": True,\n",
    "            \"loss_scale\": 0,\n",
    "            \"loss_scale_window\": 1000,\n",
    "            \"initial_scale_power\": 16,\n",
    "            \"hysteresis\": 2,\n",
    "            \"min_loss_scale\": 1\n",
    "        },\n",
    "        \"gradient_clipping\": 1.0,\n",
    "        \"wall_clock_breakdown\": True\n",
    "    }\n",
    "\n",
    "def setup_deepspeed_distributed():\n",
    "    \"\"\"Setup distributed training for DeepSpeed\"\"\"\n",
    "    if 'RANK' not in os.environ:\n",
    "        # Single GPU setup\n",
    "        os.environ['RANK'] = '0'\n",
    "        os.environ['WORLD_SIZE'] = '1'\n",
    "        os.environ['MASTER_ADDR'] = 'localhost'\n",
    "        os.environ['MASTER_PORT'] = '12355'\n",
    "        os.environ['LOCAL_RANK'] = '0'\n",
    "    \n",
    "    # Initialize distributed\n",
    "    if not dist.is_initialized():\n",
    "        dist.init_process_group(backend='nccl')\n",
    "    \n",
    "    local_rank = int(os.environ['LOCAL_RANK'])\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    \n",
    "    return local_rank\n",
    "\n",
    "def train_with_deepspeed_zero1():\n",
    "    \"\"\"Train ViT with DeepSpeed ZeRO-1\"\"\"\n",
    "    print(\"Starting DeepSpeed ZeRO-1 training...\")\n",
    "    \n",
    "    # Setup distributed\n",
    "    local_rank = setup_deepspeed_distributed()\n",
    "    device = torch.device(f'cuda:{local_rank}')\n",
    "    \n",
    "    # Model\n",
    "    model = create_vit_model(num_classes=1000, use_pretrained=False)\n",
    "    \n",
    "    # Data loaders\n",
    "    train_loader, val_loader = get_imagenet_loaders(batch_size=8)  # Micro batch size\n",
    "    \n",
    "    # DeepSpeed config\n",
    "    ds_config = get_deepspeed_config_zero1()\n",
    "    \n",
    "    # Initialize DeepSpeed\n",
    "    model_engine, optimizer, train_loader, _ = deepspeed.initialize(\n",
    "        args=None,\n",
    "        model=model,\n",
    "        model_parameters=model.parameters(),\n",
    "        training_data=train_loader.dataset,\n",
    "        config=ds_config\n",
    "    )\n",
    "    \n",
    "    # Profiling setup\n",
    "    gpu_monitor = GPUMonitor(device_id=local_rank)\n",
    "    gpu_monitor.start()\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    results = []\n",
    "    \n",
    "    # Training loop\n",
    "    with TorchProfiler(log_dir=\\\"./logs/deepspeed_zero1\\\") as profiler:\\n        for epoch in range(2):\\n            print(f\\\"\\\\n=== DeepSpeed ZeRO-1 Epoch {epoch + 1} ===\\\")\\n            \\n            model_engine.train()\\n            losses = AverageMeter()\\n            top1 = AverageMeter()\\n            \\n            for i, (images, targets) in enumerate(train_loader):\\n                images = images.to(device, non_blocking=True)\\n                targets = targets.to(device, non_blocking=True)\\n                \\n                # Forward pass\\n                outputs = model_engine(images)\\n                loss = criterion(outputs, targets)\\n                \\n                # Backward pass\\n                model_engine.backward(loss)\\n                model_engine.step()\\n                \\n                # Metrics\\n                acc1, _ = calculate_accuracy(outputs, targets, topk=(1, 5))\\n                losses.update(loss.item(), images.size(0))\\n                top1.update(acc1.item(), images.size(0))\\n                \\n                if profiler:\\n                    profiler.step()\\n                \\n                if i % 10 == 0 and local_rank == 0:\\n                    print(f'Epoch: [{epoch}][{i}/{len(train_loader)}] '\\n                          f'Loss {losses.val:.4f} ({losses.avg:.4f}) '\\n                          f'Acc@1 {top1.val:.3f} ({top1.avg:.3f})')\\n                    \\n                    # GPU stats\\n                    stats = gpu_monitor.get_stats()\\n                    if stats:\\n                        print(f'GPU: {stats.get(\\\"gpu_util_avg\\\", 0):.1f}% util, '\\n                              f'{stats.get(\\\"gpu_memory_avg\\\", 0):.1f}GB mem')\\n                \\n                if i >= 50:  # Limit for demo\\n                    break\\n            \\n            # Validation\\n            if local_rank == 0:\\n                val_metrics = validate(model_engine, val_loader, criterion, device)\\n                \\n                epoch_results = {\\n                    'epoch': epoch + 1,\\n                    'method': 'DeepSpeed ZeRO-1',\\n                    'train_loss': losses.avg,\\n                    'train_acc1': top1.avg,\\n                    'val_loss': val_metrics['loss'],\\n                    'val_acc1': val_metrics['top1'],\\n                    'gpu_stats': gpu_monitor.get_stats()\\n                }\\n                results.append(epoch_results)\\n    \\n    # Cleanup\\n    gpu_monitor.stop()\\n    if local_rank == 0:\\n        gpu_monitor.plot_metrics(save_path='gpu_metrics_zero1.png')\\n        \\n        with open('training_results_zero1.json', 'w') as f:\\n            json.dump(results, f, indent=2)\\n    \\n    # Memory stats\\n    if local_rank == 0:\\n        print(\\\"\\\\nDeepSpeed ZeRO-1 Memory Stats:\\\")\\n        print(f\\\"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\\\")\\n        print(f\\\"Peak GPU memory: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB\\\")\\n        \\n        # DeepSpeed memory breakdown\\n        memory_breakdown = model_engine.memory_breakdown()\\n        for key, value in memory_breakdown.items():\\n            if isinstance(value, (int, float)):\\n                print(f\\\"{key}: {value / 1024**3:.2f} GB\\\")\\n    \\n    print(\\\"\\\\nDeepSpeed ZeRO-1 training completed!\\\")\\n    return results\\n\\n# Run if this cell is executed\\nif __name__ == \\\"__main__\\\":\\n    results = train_with_deepspeed_zero1()\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b253d81",
   "metadata": {},
   "source": [
    "## DeepSpeed ZeRO Stage 2\n",
    "\n",
    "ZeRO-2 partitions both optimizer states and gradients, further reducing memory usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fdd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deepspeed_config_zero2():\n",
    "    \"\"\"DeepSpeed configuration for ZeRO Stage 2\"\"\"\n",
    "    config = get_deepspeed_config_zero1()  # Start with ZeRO-1 config\n",
    "    \n",
    "    # Update to ZeRO Stage 2\n",
    "    config[\"zero_optimization\"][\"stage\"] = 2\n",
    "    config[\"zero_optimization\"][\"cpu_offload\"] = False  # Keep on GPU for A100\n",
    "    \n",
    "    return config\n",
    "\n",
    "def train_with_deepspeed_zero2():\n",
    "    \"\"\"Train ViT with DeepSpeed ZeRO-2\"\"\"\n",
    "    print(\"Starting DeepSpeed ZeRO-2 training...\")\n",
    "    \n",
    "    # Setup distributed\n",
    "    local_rank = setup_deepspeed_distributed()\n",
    "    device = torch.device(f'cuda:{local_rank}')\n",
    "    \n",
    "    # Model\n",
    "    model = create_vit_model(num_classes=1000, use_pretrained=False)\n",
    "    \n",
    "    # Data loaders\n",
    "    train_loader, val_loader = get_imagenet_loaders(batch_size=8)\n",
    "    \n",
    "    # DeepSpeed config\n",
    "    ds_config = get_deepspeed_config_zero2()\n",
    "    \n",
    "    # Initialize DeepSpeed\n",
    "    model_engine, optimizer, train_loader, _ = deepspeed.initialize(\n",
    "        args=None,\n",
    "        model=model,\n",
    "        model_parameters=model.parameters(),\n",
    "        training_data=train_loader.dataset,\n",
    "        config=ds_config\n",
    "    )\n",
    "    \n",
    "    # Profiling setup\n",
    "    gpu_monitor = GPUMonitor(device_id=local_rank)\n",
    "    gpu_monitor.start()\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    results = []\n",
    "    \n",
    "    # Training loop\n",
    "    with TorchProfiler(log_dir=\"./logs/deepspeed_zero2\") as profiler:\n",
    "        for epoch in range(2):\n",
    "            print(f\"\\n=== DeepSpeed ZeRO-2 Epoch {epoch + 1} ===\")\n",
    "            \n",
    "            model_engine.train()\n",
    "            losses = AverageMeter()\n",
    "            top1 = AverageMeter()\n",
    "            \n",
    "            for i, (images, targets) in enumerate(train_loader):\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                targets = targets.to(device, non_blocking=True)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model_engine(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Backward pass\n",
    "                model_engine.backward(loss)\n",
    "                model_engine.step()\n",
    "                \n",
    "                # Metrics\n",
    "                acc1, _ = calculate_accuracy(outputs, targets, topk=(1, 5))\n",
    "                losses.update(loss.item(), images.size(0))\n",
    "                top1.update(acc1.item(), images.size(0))\n",
    "                \n",
    "                if profiler:\n",
    "                    profiler.step()\n",
    "                \n",
    "                if i % 10 == 0 and local_rank == 0:\n",
    "                    print(f'Epoch: [{epoch}][{i}/{len(train_loader)}] '\n",
    "                          f'Loss {losses.val:.4f} ({losses.avg:.4f}) '\n",
    "                          f'Acc@1 {top1.val:.3f} ({top1.avg:.3f})')\n",
    "                    \n",
    "                    # GPU stats\n",
    "                    stats = gpu_monitor.get_stats()\n",
    "                    if stats:\n",
    "                        print(f'GPU: {stats.get(\"gpu_util_avg\", 0):.1f}% util, '\n",
    "                              f'{stats.get(\"gpu_memory_avg\", 0):.1f}GB mem')\n",
    "                \n",
    "                if i >= 50:  # Limit for demo\n",
    "                    break\n",
    "            \n",
    "            # Validation\n",
    "            if local_rank == 0:\n",
    "                val_metrics = validate(model_engine, val_loader, criterion, device)\n",
    "                \n",
    "                epoch_results = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'method': 'DeepSpeed ZeRO-2',\n",
    "                    'train_loss': losses.avg,\n",
    "                    'train_acc1': top1.avg,\n",
    "                    'val_loss': val_metrics['loss'],\n",
    "                    'val_acc1': val_metrics['top1'],\n",
    "                    'gpu_stats': gpu_monitor.get_stats()\n",
    "                }\n",
    "                results.append(epoch_results)\n",
    "    \n",
    "    # Cleanup\n",
    "    gpu_monitor.stop()\n",
    "    if local_rank == 0:\n",
    "        gpu_monitor.plot_metrics(save_path='gpu_metrics_zero2.png')\n",
    "        \n",
    "        with open('training_results_zero2.json', 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "    \n",
    "    # Memory stats\n",
    "    if local_rank == 0:\n",
    "        print(\"\\nDeepSpeed ZeRO-2 Memory Stats:\")\n",
    "        print(f\"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n",
    "        print(f\"Peak GPU memory: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB\")\n",
    "        \n",
    "        # DeepSpeed memory breakdown\n",
    "        memory_breakdown = model_engine.memory_breakdown()\n",
    "        for key, value in memory_breakdown.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"{key}: {value / 1024**3:.2f} GB\")\n",
    "    \n",
    "    print(\"\\nDeepSpeed ZeRO-2 training completed!\")\n",
    "    return results\n",
    "\n",
    "# Run if this cell is executed\n",
    "if __name__ == \"__main__\":\n",
    "    results = train_with_deepspeed_zero2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a330e",
   "metadata": {},
   "source": [
    "## DeepSpeed ZeRO Stage 3\n",
    "\n",
    "ZeRO-3 partitions model parameters, gradients, and optimizer states for maximum memory efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2440d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deepspeed_config_zero3():\n",
    "    \"\"\"DeepSpeed configuration for ZeRO Stage 3\"\"\"\n",
    "    config = get_deepspeed_config_zero1()  # Start with ZeRO-1 config\n",
    "    \n",
    "    # Update to ZeRO Stage 3\n",
    "    config[\"zero_optimization\"][\"stage\"] = 3\n",
    "    config[\"zero_optimization\"][\"stage3_max_live_parameters\"] = 1e9\n",
    "    config[\"zero_optimization\"][\"stage3_max_reuse_distance\"] = 1e9\n",
    "    config[\"zero_optimization\"][\"stage3_prefetch_bucket_size\"] = 5e8\n",
    "    config[\"zero_optimization\"][\"stage3_param_persistence_threshold\"] = 1e6\n",
    "    config[\"zero_optimization\"][\"sub_group_size\"] = 1e9\n",
    "    config[\"zero_optimization\"][\"reduce_bucket_size\"] = 5e8\n",
    "    \n",
    "    # CPU offload for extreme memory savings (optional)\n",
    "    config[\"zero_optimization\"][\"offload_optimizer\"] = {\n",
    "        \"device\": \"cpu\",\n",
    "        \"pin_memory\": True\n",
    "    }\n",
    "    config[\"zero_optimization\"][\"offload_param\"] = {\n",
    "        \"device\": \"cpu\",\n",
    "        \"pin_memory\": True\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "def train_with_deepspeed_zero3():\n",
    "    \"\"\"Train ViT with DeepSpeed ZeRO-3\"\"\"\n",
    "    print(\"Starting DeepSpeed ZeRO-3 training...\")\n",
    "    \n",
    "    # Setup distributed\n",
    "    local_rank = setup_deepspeed_distributed()\n",
    "    device = torch.device(f'cuda:{local_rank}')\n",
    "    \n",
    "    # Model\n",
    "    model = create_vit_model(num_classes=1000, use_pretrained=False)\n",
    "    \n",
    "    # Data loaders\n",
    "    train_loader, val_loader = get_imagenet_loaders(batch_size=16)  # Can use larger batch with ZeRO-3\n",
    "    \n",
    "    # DeepSpeed config\n",
    "    ds_config = get_deepspeed_config_zero3()\n",
    "    \n",
    "    # Initialize DeepSpeed\n",
    "    model_engine, optimizer, train_loader, _ = deepspeed.initialize(\n",
    "        args=None,\n",
    "        model=model,\n",
    "        model_parameters=model.parameters(),\n",
    "        training_data=train_loader.dataset,\n",
    "        config=ds_config\n",
    "    )\n",
    "    \n",
    "    # Profiling setup\n",
    "    gpu_monitor = GPUMonitor(device_id=local_rank)\n",
    "    gpu_monitor.start()\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    results = []\n",
    "    \n",
    "    # Training loop\n",
    "    with TorchProfiler(log_dir=\"./logs/deepspeed_zero3\") as profiler:\n",
    "        for epoch in range(2):\n",
    "            print(f\"\\n=== DeepSpeed ZeRO-3 Epoch {epoch + 1} ===\")\n",
    "            \n",
    "            model_engine.train()\n",
    "            losses = AverageMeter()\n",
    "            top1 = AverageMeter()\n",
    "            \n",
    "            for i, (images, targets) in enumerate(train_loader):\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                targets = targets.to(device, non_blocking=True)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model_engine(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Backward pass\n",
    "                model_engine.backward(loss)\n",
    "                model_engine.step()\n",
    "                \n",
    "                # Metrics\n",
    "                acc1, _ = calculate_accuracy(outputs, targets, topk=(1, 5))\n",
    "                losses.update(loss.item(), images.size(0))\n",
    "                top1.update(acc1.item(), images.size(0))\n",
    "                \n",
    "                if profiler:\n",
    "                    profiler.step()\n",
    "                \n",
    "                if i % 10 == 0 and local_rank == 0:\n",
    "                    print(f'Epoch: [{epoch}][{i}/{len(train_loader)}] '\n",
    "                          f'Loss {losses.val:.4f} ({losses.avg:.4f}) '\n",
    "                          f'Acc@1 {top1.val:.3f} ({top1.avg:.3f})')\n",
    "                    \n",
    "                    # GPU stats\n",
    "                    stats = gpu_monitor.get_stats()\n",
    "                    if stats:\n",
    "                        print(f'GPU: {stats.get(\"gpu_util_avg\", 0):.1f}% util, '\n",
    "                              f'{stats.get(\"gpu_memory_avg\", 0):.1f}GB mem')\n",
    "                \n",
    "                if i >= 50:  # Limit for demo\n",
    "                    break\n",
    "            \n",
    "            # Validation\n",
    "            if local_rank == 0:\n",
    "                val_metrics = validate(model_engine, val_loader, criterion, device)\n",
    "                \n",
    "                epoch_results = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'method': 'DeepSpeed ZeRO-3',\n",
    "                    'train_loss': losses.avg,\n",
    "                    'train_acc1': top1.avg,\n",
    "                    'val_loss': val_metrics['loss'],\n",
    "                    'val_acc1': val_metrics['top1'],\n",
    "                    'gpu_stats': gpu_monitor.get_stats()\n",
    "                }\n",
    "                results.append(epoch_results)\n",
    "    \n",
    "    # Cleanup\n",
    "    gpu_monitor.stop()\n",
    "    if local_rank == 0:\n",
    "        gpu_monitor.plot_metrics(save_path='gpu_metrics_zero3.png')\n",
    "        \n",
    "        with open('training_results_zero3.json', 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "    \n",
    "    # Memory stats\n",
    "    if local_rank == 0:\n",
    "        print(\"\\nDeepSpeed ZeRO-3 Memory Stats:\")\n",
    "        print(f\"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n",
    "        print(f\"Peak GPU memory: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB\")\n",
    "        \n",
    "        # DeepSpeed memory breakdown\n",
    "        memory_breakdown = model_engine.memory_breakdown()\n",
    "        for key, value in memory_breakdown.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"{key}: {value / 1024**3:.2f} GB\")\n",
    "    \n",
    "    print(\"\\nDeepSpeed ZeRO-3 training completed!\")\n",
    "    return results\n",
    "\n",
    "# Run if this cell is executed\n",
    "if __name__ == \"__main__\":\n",
    "    results = train_with_deepspeed_zero3()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa5d862",
   "metadata": {},
   "source": [
    "## Results Comparison and Analysis\n",
    "\n",
    "Compare performance and GPU utilization across all training methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_training_results():\n",
    "    \"\"\"Analyze and compare all training results\"\"\"\n",
    "    print(\"Analyzing training results...\")\n",
    "    \n",
    "    # Load all result files\n",
    "    result_files = glob.glob(\"training_results_*.json\")\n",
    "    all_results = {}\n",
    "    \n",
    "    for file in result_files:\n",
    "        method = file.replace(\"training_results_\", \"\").replace(\".json\", \"\")\n",
    "        try:\n",
    "            with open(file, 'r') as f:\n",
    "                all_results[method] = json.load(f)\n",
    "                print(f\"[LOADED] {method} results\")\n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: Could not load {file}: {e}\")\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"No results found. Run training cells first.\")\n",
    "        return\n",
    "    \n",
    "    # Create comparison plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Training Loss Comparison\n",
    "    ax = axes[0, 0]\n",
    "    for method, results in all_results.items():\n",
    "        epochs = [r['epoch'] for r in results]\n",
    "        losses = [r['train']['loss'] if 'train' in r else r['train_loss'] for r in results]\n",
    "        ax.plot(epochs, losses, marker='o', label=method, linewidth=2)\n",
    "    ax.set_title('Training Loss Comparison')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Validation Accuracy Comparison\n",
    "    ax = axes[0, 1]\n",
    "    for method, results in all_results.items():\n",
    "        epochs = [r['epoch'] for r in results]\n",
    "        accs = [r['val']['top1'] if 'val' in r else r['val_acc1'] for r in results]\n",
    "        ax.plot(epochs, accs, marker='s', label=method, linewidth=2)\n",
    "    ax.set_title('Validation Accuracy Comparison')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Top-1 Accuracy (%)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. GPU Memory Usage\n",
    "    ax = axes[1, 0]\n",
    "    methods = []\n",
    "    memory_usage = []\n",
    "    for method, results in all_results.items():\n",
    "        if results and 'gpu_stats' in results[-1]:\n",
    "            methods.append(method)\n",
    "            memory_usage.append(results[-1]['gpu_stats'].get('gpu_memory_max', 0))\n",
    "    \n",
    "    if methods:\n",
    "        bars = ax.bar(methods, memory_usage, color=['skyblue', 'lightcoral', 'lightgreen', 'orange'][:len(methods)])\n",
    "        ax.set_title('Peak GPU Memory Usage')\n",
    "        ax.set_ylabel('Memory (GB)')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, memory_usage):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                   f'{value:.1f}GB', ha='center', va='bottom')\n",
    "    \n",
    "    # 4. GPU Utilization\n",
    "    ax = axes[1, 1]\n",
    "    methods = []\n",
    "    gpu_util = []\n",
    "    for method, results in all_results.items():\n",
    "        if results and 'gpu_stats' in results[-1]:\n",
    "            methods.append(method)\n",
    "            gpu_util.append(results[-1]['gpu_stats'].get('gpu_util_avg', 0))\n",
    "    \n",
    "    if methods:\n",
    "        bars = ax.bar(methods, gpu_util, color=['skyblue', 'lightcoral', 'lightgreen', 'orange'][:len(methods)])\n",
    "        ax.set_title('Average GPU Utilization')\n",
    "        ax.set_ylabel('Utilization (%)')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, gpu_util):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                   f'{value:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\nTraining Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    summary_data = []\n",
    "    \n",
    "    for method, results in all_results.items():\n",
    "        if not results:\n",
    "            continue\n",
    "            \n",
    "        final_result = results[-1]\n",
    "        summary = {\n",
    "            'Method': method,\n",
    "            'Final Train Loss': final_result.get('train', {}).get('loss') or final_result.get('train_loss', 'N/A'),\n",
    "            'Final Val Acc@1': final_result.get('val', {}).get('top1') or final_result.get('val_acc1', 'N/A'),\n",
    "            'Peak GPU Memory (GB)': final_result.get('gpu_stats', {}).get('gpu_memory_max', 'N/A'),\n",
    "            'Avg GPU Util (%)': final_result.get('gpu_stats', {}).get('gpu_util_avg', 'N/A'),\n",
    "            'Avg Power (W)': final_result.get('gpu_stats', {}).get('power_avg', 'N/A'),\n",
    "        }\n",
    "        summary_data.append(summary)\n",
    "    \n",
    "    if summary_data:\n",
    "        df = pd.DataFrame(summary_data)\n",
    "        print(df.to_string(index=False, float_format='%.2f'))\n",
    "    \n",
    "    print(\"\\nKey Insights:\")\n",
    "    print(\"- ZeRO-1: Partitions optimizer states - moderate memory savings\")\n",
    "    print(\"- ZeRO-2: Partitions optimizer + gradients - better memory efficiency\")\n",
    "    print(\"- ZeRO-3: Partitions all states - maximum memory savings, some overhead\")\n",
    "    print(\"- Basic training: No optimizations - highest memory usage\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def create_profiling_commands():\n",
    "    \"\"\"Generate commands for external profiling tools\"\"\"\n",
    "    print(\"\\nExternal Profiling Commands:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Nsight Systems\n",
    "    print(\"1. NVIDIA Nsight Systems:\")\n",
    "    print(\"   nsys profile --trace=cuda,nvtx,osrt,cudnn,cublas -o vit_training python training_script.py\")\n",
    "    \n",
    "    # Nsight Compute\n",
    "    print(\"\\n2. NVIDIA Nsight Compute:\")\n",
    "    print(\"   ncu --set full --export vit_kernels python training_script.py\")\n",
    "    \n",
    "    # nvprof (legacy)\n",
    "    print(\"\\n3. nvprof (legacy):\")\n",
    "    print(\"   nvprof --print-gpu-trace --export-profile vit_profile.nvvp python training_script.py\")\n",
    "    \n",
    "    # PyTorch Profiler TensorBoard\n",
    "    print(\"\\n4. View PyTorch Profiler in TensorBoard:\")\n",
    "    print(\"   tensorboard --logdir=./logs/\")\n",
    "    \n",
    "    # Memory profiler\n",
    "    print(\"\\n5. Memory profiling:\")\n",
    "    print(\"   python -m memory_profiler training_script.py\")\n",
    "    \n",
    "    if COLAB:\n",
    "        print(\"\\nNote: In Colab, use the following to install TensorBoard:\")\n",
    "        print(\"   %load_ext tensorboard\")\n",
    "        print(\"   %tensorboard --logdir=./logs/\")\n",
    "\n",
    "def run_comprehensive_analysis():\n",
    "    \"\"\"Run all training methods and compare results\"\"\"\n",
    "    print(\"Running comprehensive training analysis...\")\n",
    "    \n",
    "    methods = [\n",
    "        (\"Basic Training\", main_training_basic),\n",
    "        (\"DeepSpeed ZeRO-1\", train_with_deepspeed_zero1),\n",
    "        (\"DeepSpeed ZeRO-2\", train_with_deepspeed_zero2),\n",
    "        (\"DeepSpeed ZeRO-3\", train_with_deepspeed_zero3),\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for method_name, method_func in methods:\n",
    "        try:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Running {method_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            result = method_func()\n",
    "            results[method_name] = result\n",
    "            \n",
    "            print(f\"[SUCCESS] {method_name} completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[FAILED] {method_name} failed: {e}\")\n",
    "            results[method_name] = None\n",
    "    \n",
    "    # Analyze results\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"COMPREHENSIVE ANALYSIS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    analyze_training_results()\n",
    "    create_profiling_commands()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Option 1: Analyze existing results\n",
    "    analyze_training_results()\n",
    "    \n",
    "    # Option 2: Run all methods and analyze (uncomment to run)\n",
    "    # comprehensive_results = run_comprehensive_analysis()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
